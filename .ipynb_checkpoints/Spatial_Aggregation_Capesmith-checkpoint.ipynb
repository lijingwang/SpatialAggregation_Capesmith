{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Lijing Wang, lijing52@stanford.edu (2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib\n",
    "import rioxarray\n",
    "import matplotlib as mpl\n",
    "import warnings\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay,PrecisionRecallDisplay\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#mpl.rcParams['figure.dpi'] = 144\n",
    "plt.rcParams.update({'font.size': 13})\n",
    "\n",
    "## bounding box\n",
    "bbox = (546400,554100,6817000,6821500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Domain size: ~ 7.7 km x 4.5 km \n",
    "\n",
    "Grid resolution: 6m "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input, remote sensing bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_dir_list: dir list include all .tif (input data)\n",
    "X_dir_list = [filename for filename in os.listdir('.') if filename.endswith(\".tif\")]\n",
    "X_dir_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all X gridded data: \n",
    "name_list = [X_dir.split('.')[0] for X_dir in X_dir_list]\n",
    "name_show_list = ['band0: “red” 630-690nm','band1: “near-red edge” 705nm-745nm',\n",
    "                  'band2: “coastal” 400-450nm','band3: “blue” 450-510nm',\n",
    "                  'band4: “green” 510-580nm','band5: “yellow” 585-625nm',\n",
    "                  'band6: near-IR1 770-895nm','band7: near-IR2 860-1040nm']\n",
    "[name_show_list.append(name) for name in ['ferric_silicate','ferrous_silicate','fe2','fe3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all WV_band data: \n",
    "WV_band = {}\n",
    "plt.figure(figsize=(18,6))\n",
    "for i,name in enumerate(name_list): \n",
    "    ax = plt.subplot(2, 4, i+1)\n",
    "    load = rioxarray.open_rasterio(X_dir_list[i],data_name=name)\n",
    "    load = load.sel(band=1)\n",
    "    \n",
    "    WV_band[name] = load.data\n",
    "    plt.imshow(WV_band[name],extent=bbox,vmin = 0,vmax = 500)\n",
    "    plt.axis('off')\n",
    "    plt.colorbar(shrink= 0.6)\n",
    "    plt.title(name_show_list[i], fontdict = {'fontsize' : 13})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output: Rock type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load target classes\n",
    "Day1 = gpd.read_file(\"Day1.gpkg\")\n",
    "Day20 = gpd.read_file(\"Day20_2classes.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB vis\n",
    "def display_rgb(img, b_r, b_g, b_b, alpha=1.):\n",
    "    rgb = np.stack([img[b_r], img[b_g], img[b_b]], axis=-1)\n",
    "    rgb = rgb/300 * alpha\n",
    "    return rgb\n",
    "rgb = display_rgb(WV_band, 'band00', 'band05', 'band02', alpha=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.imshow(rgb,extent=bbox,alpha = 1)\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.imshow(rgb,extent=bbox,alpha = 1)\n",
    "ax.scatter(Day1['x'],Day1['y'],c = Day1['target_vals'],s = 10,cmap ='hsv',vmin = 0,vmax = 3)\n",
    "ax.axis('off')\n",
    "ax.set_title('Day 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.imshow(rgb,extent=bbox,alpha = 1)\n",
    "ax.scatter(Day20['x'],Day20['y'],c = Day20['target_vals'],s = 10,cmap ='hsv',vmin = 0,vmax = 3)\n",
    "ax.axis('off')\n",
    "ax.set_title('Day 20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Land cover mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate normalized difference vegetation index (NDVI)\n",
    "NDVI = (WV_band['band07']-WV_band['band00'])/(WV_band['band07']+WV_band['band00'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "cmap = plt.get_cmap('Spectral', 10)\n",
    "plt.imshow(NDVI,extent=bbox,cmap = cmap,vmin = -1,vmax = 1)\n",
    "plt.colorbar(shrink = 0.7,ticks=[-1, 0,0.2,1])\n",
    "ax.axis('off')\n",
    "plt.title('NDVI: Normalized Difference Vegetation Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# land cover mask inferred from NDVI\n",
    "cover_type = np.zeros(NDVI.shape)+1\n",
    "cover_type[NDVI>0.2] = 2\n",
    "cover_type[NDVI<0] = 0\n",
    "mask = np.load('mask.npy')\n",
    "cover_type[(cover_type==1) & (mask==0)] = 2\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "cmap = plt.get_cmap('BrBG_r', 100)\n",
    "plt.imshow(cover_type,extent=bbox,cmap = cmap,vmin = -2,vmax = 2)\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rasterize output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rasterize_output(output):\n",
    "    min_x = bbox[0]\n",
    "    max_y = bbox[3]\n",
    "    res = 6\n",
    "    nx = WV_band['band00'].shape[0]\n",
    "    ny = WV_band['band00'].shape[1]\n",
    "    gridded_x = (np.array((output['x']-min_x)/res,dtype = 'int'))\n",
    "    gridded_y = (np.array((max_y-output['y'])/res,dtype = 'int'))\n",
    "    gridded = np.zeros((ny,nx))\n",
    "    gridded[:] = np.nan\n",
    "    gridded[gridded_x,gridded_y] = np.array(output['target_vals'])\n",
    "    \n",
    "    return gridded.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Day1_raster = rasterize_output(Day1)\n",
    "Day20_raster = rasterize_output(Day20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all rasters as one matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = np.zeros((WV_band['band00'].shape[0]*WV_band['band00'].shape[1],len(name_list)))\n",
    "for i,name in enumerate(name_list):\n",
    "    X_all[:,i] = WV_band[name].reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract data with measured rock type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Day1 = X_all[~np.isnan(Day1_raster.reshape(-1)),:]\n",
    "y_Day1 = Day1_raster[~np.isnan(Day1_raster)]\n",
    "X_Day20 = X_all[~np.isnan(Day20_raster.reshape(-1)),:]\n",
    "y_Day20 = Day20_raster[~np.isnan(Day20_raster)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification task with different methods\n",
    "- Bayes\n",
    "- Naïve Bayes\n",
    "- Logistic Regression\n",
    "- CART\n",
    "- Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X, y\n",
    "## You can change it into Day 1 or Day 20\n",
    "Day = 'Day1'\n",
    "\n",
    "if Day == 'Day1':\n",
    "    X = np.copy(X_Day1)\n",
    "    y = np.copy(y_Day1)\n",
    "elif Day == 'Day20': \n",
    "    X = np.copy(X_Day20)\n",
    "    y = np.copy(y_Day20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes with one variable\n",
    "p(c|x) = p(x|c)p(c)/p(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select one variable x: band00\n",
    "selected_band = 'band00'\n",
    "selected_index = np.where(selected_band==np.array(name_list))[0][0]\n",
    "\n",
    "# calculate priors and likelihoods\n",
    "from scipy import stats\n",
    "priors = [np.sum(y_train==i)/len(y_train) for i in range(len(np.unique(y_train)))]\n",
    "likelihoods = [stats.gaussian_kde(X_train[y_train==i,selected_index])\n",
    "               for i in range(len(np.unique(y_train)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize likelihood p(x|c)\n",
    "X_train_pd = pd.DataFrame(X_train,columns=name_list)\n",
    "X_train_pd['y'] = np.array(y_train,dtype = 'int64')\n",
    "X_train_pd['weight'] = X_train_pd['y']\n",
    "for i in range(len(np.unique(y_train))):\n",
    "    X_train_pd['weight'][X_train_pd['y']==i] = 1/np.sum(X_train_pd['y']==i)\n",
    "\n",
    "sns.histplot(data=X_train_pd, x=selected_band, hue=\"y\",stat=\"count\", weights = 'weight',\n",
    "             kde=True, palette = 'hsv',element=\"step\", fill=True,bins = 20,hue_norm=(0,3))\n",
    "plt.ylabel('density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the posterior p(c|x)\n",
    "def posterior_Bayes(x,likelihoods,priors):\n",
    "    pos= [likelihoods[i](x)*priors[i] for i in range(len(likelihoods))]\n",
    "    pos=pos/np.sum(pos,axis =0)\n",
    "    return pos.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix on test data\n",
    "results['Bayes: x'] = posterior_Bayes(X_test[:,selected_index],likelihoods,priors)\n",
    "y_pred = np.argmax(results['Bayes: x'],axis = 1)\n",
    "if len(priors)==3:\n",
    "    class_label= ['0: peridotite','1: basalt','2: gabbro']\n",
    "elif len(priors)==2:\n",
    "    class_label= ['0: peridotite','1: basalt']\n",
    "cm = confusion_matrix(np.array(y_test,dtype ='int64'), y_pred, labels=np.unique(y_pred), normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=class_label)\n",
    "disp.plot(cmap = 'Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(posterior_Bayes(X_all[:,selected_index],likelihoods,priors),axis = 1)\n",
    "y_pred = np.array(y_pred.reshape(WV_band['band00'].shape),dtype = 'float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_type_vis = np.copy(cover_type)\n",
    "cover_type_vis[cover_type_vis==1] = np.nan\n",
    "plt.imshow(y_pred,cmap ='hsv',vmin = 0,vmax = 3)\n",
    "plt.imshow(cover_type_vis,cmap = 'BrBG_r',alpha = 1,vmin = -2,vmax = 2)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naïve Bayes with two variables\n",
    "p(c|x1,x2) = p(x1|c)p(x2|c)p(c)/p(x1,x2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_band_list = ['band00','band07']\n",
    "plt.figure(figsize=(15,13))\n",
    "for i in range(len(priors)): \n",
    "    ax = plt.subplot(2, 2, i+1)\n",
    "    sns.scatterplot(data=X_train_pd[X_train_pd['y']==i], \n",
    "                    x=selected_band_list[0], \n",
    "                    y=selected_band_list[1],hue = 'y',palette = 'hsv',hue_norm=(0,4))\n",
    "    corr = np.corrcoef(X_train_pd[X_train_pd['y']==i][selected_band_list[0]],\n",
    "                       X_train_pd[X_train_pd['y']==i][selected_band_list[1]])[0,1]\n",
    "    ax.set_title('Correlation coefficient:'+str(np.round(corr,2)))\n",
    "\n",
    "ax = plt.subplot(2, 2, len(priors)+1)\n",
    "sns.scatterplot(data=X_train_pd, x=selected_band_list[0], y=selected_band_list[1],hue = 'y',palette = 'hsv',hue_norm=(0,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_band_list = ['band00','band07']\n",
    "plt.figure(figsize=(15,13))\n",
    "for i in range(len(priors)): \n",
    "    ax = plt.subplot(2, 2, i+1)\n",
    "    sns.kdeplot(data=X_train_pd[X_train_pd['y']==i], \n",
    "                    x=selected_band_list[0], \n",
    "                    y=selected_band_list[1],hue = 'y',palette = 'hsv',hue_norm=(0,4),fill=True)\n",
    "    corr = np.corrcoef(X_train_pd[X_train_pd['y']==i][selected_band_list[0]],\n",
    "                       X_train_pd[X_train_pd['y']==i][selected_band_list[1]])[0,1]\n",
    "    ax.set_title('Correlation coefficient:'+str(np.round(corr,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate likelihoods\n",
    "likelihoods_list = {}\n",
    "for selected_band in selected_band_list:\n",
    "    selected_index = np.where(selected_band==np.array(name_list))[0][0]\n",
    "    likelihoods = [stats.gaussian_kde(X_train[y_train==i,selected_index])\n",
    "                   for i in range(len(np.unique(y_train)))]\n",
    "    likelihoods_list[selected_band] = likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the posterior p(c|x1,x2) = p(x1|c)p(x2|c)p(c)/p(x1,x2) \n",
    "def posterior_Naive(x,priors,likelihoods_list):\n",
    "    selected_band = selected_band_list[0]\n",
    "    likelihoods = likelihoods_list[selected_band]\n",
    "    selected_index = np.where(selected_band==np.array(name_list))[0][0]\n",
    "    \n",
    "    pos= [likelihoods[i](x[:,selected_index])*priors[i] for i in range(len(likelihoods))]\n",
    "    for selected_band in selected_band_list[1:]:\n",
    "        selected_index = np.where(selected_band==np.array(name_list))[0][0]\n",
    "        likelihoods = likelihoods_list[selected_band]\n",
    "        pos = [pos[i]*likelihoods[i](x[:,selected_index]) for i in range(len(likelihoods))]\n",
    "    pos=pos/np.sum(pos,axis =0)\n",
    "    return pos.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix on test data\n",
    "results['Naïve Bayes: x1,x2'] = posterior_Naive(X_test,priors,likelihoods_list)\n",
    "y_pred = np.argmax(results['Naïve Bayes: x1,x2'],axis = 1)\n",
    "\n",
    "if len(priors)==3:\n",
    "    class_label= ['0: peridotite','1: basalt','2: gabbro']\n",
    "elif len(priors)==2:\n",
    "    class_label= ['0: peridotite','1: basalt']\n",
    "cm = confusion_matrix(np.array(y_test,dtype ='int64'), y_pred, labels=np.unique(y_pred), normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=class_label)\n",
    "disp.plot(cmap = 'Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(posterior_Naive(X_all,priors,likelihoods_list),axis = 1)\n",
    "y_pred = np.array(y_pred.reshape(WV_band['band00'].shape),dtype = 'float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y_pred,cmap ='hsv',vmin = 0,vmax = 3)\n",
    "plt.imshow(cover_type_vis,cmap = 'BrBG_r',alpha = 1,vmin = -2,vmax = 2)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Bayes with two variables\n",
    "p(c|x1,x2) = p(x1,x2|c)p(c)/p(x1,x2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate likelihoods\n",
    "selected_index = [np.where(selected_band==np.array(name_list))[0][0] for selected_band in selected_band_list]\n",
    "likelihoods = [stats.gaussian_kde(X_train[y_train==i,:][:,selected_index].T)\n",
    "               for i in range(len(np.unique(y_train)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the posterior p(c|x1,x2) = p(x1,x2|c)p(c)/p(x1,x2) \n",
    "def posterior_full_Bayes(x,likelihoods,priors):\n",
    "    selected_index = [np.where(selected_band==np.array(name_list))[0][0] for selected_band in selected_band_list]\n",
    "    pos= [likelihoods[i](x[:,selected_index].T)*priors[i] for i in range(len(likelihoods))]\n",
    "    pos=pos/np.sum(pos,axis =0)\n",
    "    return pos.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix on test data\n",
    "results['Full Bayes: x1,x2'] = posterior_full_Bayes(X_test,likelihoods,priors)\n",
    "y_pred = np.argmax(results['Full Bayes: x1,x2'],axis = 1)\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "if len(priors)==3:\n",
    "    class_label= ['0: peridotite','1: basalt','2: gabbro']\n",
    "elif len(priors)==2:\n",
    "    class_label= ['0: peridotite','1: basalt']\n",
    "cm = confusion_matrix(np.array(y_test,dtype ='int64'), y_pred, labels=np.unique(y_pred), normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=class_label)\n",
    "disp.plot(cmap = 'Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision recall analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall(y_pred_prob,threshold,y_test = y_test):\n",
    "    prediction = (y_pred_prob[:,0]>threshold)\n",
    "    TP = np.sum(prediction[y_test==0]) # \n",
    "    PP = np.sum(prediction) # predicted positive\n",
    "    P = np.sum(y_test==0)# positive\n",
    "    precision = TP/PP\n",
    "    if np.isnan(precision):\n",
    "        precision = 1\n",
    "    recall = TP/P\n",
    "    return [precision,recall]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in results.keys():\n",
    "    PR = np.array([precision_recall(results[method],threshold) for threshold in np.linspace(0,1,100)])\n",
    "    plt.plot(PR[:,1],PR[:,0],'-', label = method)\n",
    "plt.xlabel('Recall:  % positives successfully predicted')\n",
    "plt.ylabel('Precision: \\n% positive predictions that are accurate')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Bayes: Day 1 and Day 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_map = {}\n",
    "pred_entropy = {}\n",
    "y_test_list = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Bayes: Day 1 and Day 20\n",
    "for Day in ['Day1','Day20']:\n",
    "    if Day == 'Day1':\n",
    "        X = np.copy(X_Day1)\n",
    "        y = np.copy(y_Day1)\n",
    "    elif Day == 'Day20': \n",
    "        X = np.copy(X_Day20)\n",
    "        y = np.copy(y_Day20)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "    # calculate priors\n",
    "    priors = [np.sum(y_train==i)/len(y_train) for i in range(len(np.unique(y_train)))]\n",
    "    \n",
    "    # calculate likelihoods\n",
    "    selected_index = [np.where(selected_band==np.array(name_list))[0][0] for selected_band in selected_band_list]\n",
    "    likelihoods = [stats.gaussian_kde(X_train[y_train==i,:][:,selected_index].T)\n",
    "                   for i in range(len(np.unique(y_train)))]\n",
    "    \n",
    "    # inference: test dataset\n",
    "    y_test_list[Day] = y_test\n",
    "    results['Full Bayes '+Day+': x1,x2'] = posterior_full_Bayes(X_test,likelihoods,priors)\n",
    "    \n",
    "    # inference: full map\n",
    "    y_pred_prob = posterior_full_Bayes(X_all,likelihoods,priors)\n",
    "    y_pred = np.argmax(y_pred_prob,axis = 1)\n",
    "    y_pred = np.array(y_pred.reshape(WV_band['band00'].shape),dtype = 'float64')\n",
    "    pred_map[Day] = y_pred\n",
    "    # inference: entropy\n",
    "    entropy = -y_pred_prob[:,0]*np.log10(y_pred_prob[:,0])\n",
    "    entropy = entropy.reshape(WV_band['band00'].shape)\n",
    "    pred_entropy[Day] = entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "i = 1\n",
    "for Day in ['Day1','Day20']:\n",
    "    ax = plt.subplot(1, 2, i)\n",
    "    plt.imshow(pred_map[Day],cmap ='hsv',vmin = 0,vmax = 3)\n",
    "    plt.imshow(cover_type_vis,cmap = 'BrBG_r',alpha = 1,vmin = -2,vmax = 2)\n",
    "    plt.axis('off')\n",
    "    plt.title('Prediction: '+Day)\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,7))\n",
    "i = 1\n",
    "for Day in ['Day1','Day20']:\n",
    "    ax = plt.subplot(1, 2, i)\n",
    "    plt.imshow(pred_entropy[Day],cmap = 'Blues',vmin = 0,vmax = 0.15)\n",
    "    plt.colorbar(orientation = 'horizontal',shrink = 0.7)\n",
    "    plt.imshow(cover_type_vis,cmap = 'BrBG_r',alpha = 1,vmin = -2,vmax = 2)\n",
    "    plt.axis('off')\n",
    "    plt.title('Entropy: '+Day)\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Day in ['Day1','Day20']:\n",
    "    PR = np.array([precision_recall(results['Full Bayes '+Day+': x1,x2'], threshold,\n",
    "                                    y_test_list[Day]) for threshold in np.linspace(0,1,100)])\n",
    "    plt.plot(PR[:,1],PR[:,0],'-', label = Day)\n",
    "plt.xlabel('Recall:  % positives successfully predicted')\n",
    "plt.ylabel('Precision: \\n% positive predictions that are accurate')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
